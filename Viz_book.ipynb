{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/gracer/.local/lib/python3.7/site-packages/vispy/visuals/line/line.py:395: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  ('color', np.float32, 4)])\n",
      "/Users/gracer/.local/lib/python3.7/site-packages/vispy/visuals/line/arrow.py:57: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  ('linewidth', np.float32, 1)\n",
      "/Users/gracer/.local/lib/python3.7/site-packages/vispy/visuals/isocurve.py:22: UserWarning: VisPy is not yet compatible with matplotlib 2.2+\n",
      "  warnings.warn(\"VisPy is not yet compatible with matplotlib 2.2+\")\n"
     ]
    },
    {
     "ename": "ImportError",
     "evalue": "cannot import name 'imresize' from 'scipy.misc' (/Users/gracer/anaconda3/lib/python3.7/site-packages/scipy/misc/__init__.py)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-3-b80f39161bbd>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mstatsmodels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformula\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapi\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mols\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mPIL\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 20\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mvisbrain\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mobjects\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mBrainObj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mColorbarObj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mSceneObj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mSourceObj\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     21\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mvisbrain\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mio\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mdownload_file\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mread_stc\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.7/site-packages/visbrain/objects/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;34m\"\"\"Import visbrain objects.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mbrain_obj\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mBrainObj\u001b[0m  \u001b[0;31m# noqa\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mcbar_obj\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mColorbarObj\u001b[0m  \u001b[0;31m# noqa\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mconnect_obj\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mConnectObj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mCombineConnect\u001b[0m  \u001b[0;31m# noqa\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mcrossec_obj\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mCrossSecObj\u001b[0m  \u001b[0;31m# noqa\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.7/site-packages/visbrain/objects/brain_obj.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mvispy\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mscene\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mvisbrain_obj\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mVisbrainObject\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0m_projection\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0m_project_sources_data\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvisuals\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mBrainMesh\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.7/site-packages/visbrain/objects/visbrain_obj.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mvispy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvisuals\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransforms\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mvist\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mscene_obj\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mVisbrainCanvas\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m from ..io import (write_fig_canvas, dialog_save, path_to_visbrain_data,\n\u001b[1;32m     11\u001b[0m                   \u001b[0mload_config_json\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mget_data_url_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdownload_file\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.7/site-packages/visbrain/objects/scene_obj.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mvispy\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mscene\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mio\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mwrite_fig_canvas\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmpl_preview\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdialog_save\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mcolor2vb\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mset_log_level\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrotate_turntable\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mFixedCam\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvisuals\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mCbarVisual\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.7/site-packages/visbrain/io/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mdialog\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0;34m*\u001b[0m  \u001b[0;31m# noqa\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mdownload\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0;34m*\u001b[0m  \u001b[0;31m# noqa\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mmneio\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0;34m*\u001b[0m  \u001b[0;31m# noqa\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0;34m*\u001b[0m  \u001b[0;31m# noqa\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mread_annotations\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0;34m*\u001b[0m  \u001b[0;31m# noqa\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.7/site-packages/visbrain/io/mneio.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mdatetime\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mget_dsf\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0m__all__\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m'mne_switch'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.7/site-packages/visbrain/utils/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mothers\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mphysio\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mpicture\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0msigproc\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0msleep\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.7/site-packages/visbrain/utils/picture.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;34m\"\"\"Set of functions for picture managment.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mscipy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmisc\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mimresize\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mImportError\u001b[0m: cannot import name 'imresize' from 'scipy.misc' (/Users/gracer/anaconda3/lib/python3.7/site-packages/scipy/misc/__init__.py)"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import glob\n",
    "import os\n",
    "import numpy as np\n",
    "import pickle\n",
    "import statistics\n",
    "import community\n",
    "import matplotlib as mlp\n",
    "# mlp.use(\"Qt5Agg\")\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import networkx as nx\n",
    "\n",
    "import analysis as an\n",
    "import pandas as pd\n",
    "import statsmodels as st\n",
    "import statsmodels.api as sm\n",
    "from statsmodels.formula.api import ols\n",
    "import PIL\n",
    "from visbrain.objects import BrainObj, ColorbarObj, SceneObj, SourceObj\n",
    "from visbrain.io import download_file, read_stc\n",
    "\n",
    "# from nilearn.connectome import ConnectivityMeasure\n",
    "\n",
    "# from nilearn import plotting\n",
    "#plt.matshow(rwd_mean_correlation_matrix,cmap='hot')\n",
    "\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "\n",
    "from scipy import stats as spy_stats\n",
    "import scipy\n",
    "import pprint as pp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING: pip is being invoked by an old script wrapper. This will fail in a future version of pip.\n",
      "Please see https://github.com/pypa/pip/issues/5599 for advice on fixing the underlying issue.\n",
      "To avoid this problem you can invoke Python with '-m pip' instead of running pip directly.\n",
      "Requirement already satisfied: pillow in /Users/gracer/.local/lib/python3.6/site-packages (7.2.0)\n",
      "\u001b[33mWARNING: You are using pip version 20.0.2; however, version 20.2.2 is available.\n",
      "You should consider upgrading via the '/Users/gracer/.pyenv/versions/3.6.0/bin/python3.6 -m pip install --upgrade pip' command.\u001b[0m\n",
      "pyenv: cannot rehash: /Users/gracer/.pyenv/shims isn't writable\n"
     ]
    }
   ],
   "source": [
    "! pip install --user pillow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "basepath='/Users/gracer/Google Drive/HCP/HCP_graph/1200/datasets/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = pd.read_csv(os.path.join(basepath,'tmp','mod_labels.csv'), sep=',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels.set_index('Index', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "note_dict={}\n",
    "for i,j in labels.iterrows():\n",
    "    print(i)\n",
    "    print(j['area'])\n",
    "    note_dict[i]=j['area']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "note_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "summary_dict=an.onetoughjar(os.path.join(basepath,'tmp','5_summary_dict_07-31-2020_12-26-08'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "summary_dict['NR']['ov']['modules'].keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for key, value in summary_dict['NR'].items():\n",
    "    for subkey, subvalue in value.items():\n",
    "#         print(subkey)\n",
    "        if subkey == 'modules':\n",
    "            print(subvalue.keys())\n",
    "            summary_dict['NR'][key][subkey]['Q']=community.modularity(subvalue['partition'], subvalue['graph'], weight='weight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(summary_dict['NR']['no']['modules']['Q'])\n",
    "print(summary_dict['NR']['ov']['modules']['Q'])\n",
    "print(summary_dict['NR']['ob']['modules']['Q'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for key, value in summary_dict['NR'].items():\n",
    "    for subkey, subvalue in value.items():\n",
    "#         print(subkey)\n",
    "        if subkey == 'modules':\n",
    "            print(subvalue.keys())\n",
    "            summary_dict['NR'][key][subkey]['dendrogram']=community.generate_dendrogram(subvalue['graph'],   weight='weight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "x = summary_dict['NR']['ob']['modules']['dendrogram']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "G=nx.erdos_renyi_graph(100, 0.01)\n",
    "dendo = community.generate_dendrogram(G)\n",
    "\n",
    "for level in range(len(x) - 1) :\n",
    "    print(\"partition at level\", level,\"is\", community.partition_at_level(dendo, level))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#summary_dict=an.onetoughjar(os.path.join(basepath,'tmp','5_summary_dict_12-05-2019_03-29-19'))\n",
    "\n",
    "summary_dict['NR']['no']['graphs'].nodes(data=True)\n",
    "\n",
    "x=an.grace_graph(summary_dict['NR']['no']['graphs'],'Normal weight', thresh= 97, metric = 'centrality', position='spectral', basepath = basepath)\n",
    "\n",
    "y=an.grace_graph(summary_dict['NR']['ov']['graphs'],  'Overweight',   thresh= 97, metric = 'centrality', position='spectral', basepath = basepath)\n",
    "\n",
    "z=an.grace_graph(summary_dict['NR']['ob']['graphs'], 'Obese',  thresh= 97, metric = 'centrality', position='spectral',basepath = basepath)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "summary_dict['NR']['no']['graphs'].nodes(data=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# basepath='/Users/gracer/Google Drive/HCP_graph/1200/datasets/'\n",
    "demo_dict=an.onetoughjar(os.path.join(basepath,'tmp','demo_dict_11-13-2019_02-07-22'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "demo_dict['NR'].values()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "demos=pd.DataFrame.from_dict(demo_dict['NR'], orient='index')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# demos.to_csv(os.path.join(basepath,'demos.csv'), sep=',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print(z.sort_values(by=['degree'], ascending=False).head())\n",
    "print(y.sort_values(by=['degree'], ascending=False).head())\n",
    "print(x.sort_values(by=['degree'], ascending=False).head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Full graph metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "basepath='/Users/gracer/Google Drive/HCP_graph/1200/datasets/'\n",
    "#Load data from pickle if needed\n",
    "# save_dict=an.onetoughjar(os.path.join(basepath,'tmp','save_dict_11-14-2019_02-46-01'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stat_dict={'MZ':{'mean_FC':{'no':{},'ov':{},'ob':{}}, 'clustering_coeff':{'no':{},'ov':{},'ob':{}}, 'btn_centrality':{'no':{},'ov':{},'ob':{}}, 'PC':{'no':{},'ov':{},'ob':{}}},\n",
    "           'DZ':{'mean_FC':{'no':{},'ov':{},'ob':{}}, 'clustering_coeff':{'no':{},'ov':{},'ob':{}}, 'btn_centrality':{'no':{},'ov':{},'ob':{}}, 'PC':{'no':{},'ov':{},'ob':{}}},\n",
    "           'NR':{'mean_FC':{'no':{},'ov':{},'ob':{}}, 'clustering_coeff':{'no':{},'ov':{},'ob':{}}, 'btn_centrality':{'no':{},'ov':{},'ob':{}}, 'PC':{'no':{},'ov':{},'ob':{}}}}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "stat_dict={'MZ':{'mean_FC':{'no':{},'ov':{},'ob':{}}, 'clustering_coeff':{'no':{},'ov':{},'ob':{}}, 'btn_centrality':{'no':{},'ov':{},'ob':{}}, 'PC':{'no':{},'ov':{},'ob':{}}},\n",
    "           'DZ':{'mean_FC':{'no':{},'ov':{},'ob':{}}, 'clustering_coeff':{'no':{},'ov':{},'ob':{}}, 'btn_centrality':{'no':{},'ov':{},'ob':{}}, 'PC':{'no':{},'ov':{},'ob':{}}},\n",
    "           'NR':{'mean_FC':{'no':{},'ov':{},'ob':{}}, 'clustering_coeff':{'no':{},'ov':{},'ob':{}}, 'btn_centrality':{'no':{},'ov':{},'ob':{}}, 'PC':{'no':{},'ov':{},'ob':{}}}}\n",
    "for key, value in save_dict.items():\n",
    "    for subkey,subval in value.items():\n",
    "        for k,v in subval.items():\n",
    "            if k in ['mean_FC','clustering_coeff','btn_centrality','PC']:\n",
    "                stat_dict[key][k][subkey]=pd.DataFrame.from_dict(v, 'index')\n",
    "                new_name=[]\n",
    "                for item in list(stat_dict[key][k][subkey].columns[0:100]):\n",
    "                    new_name.append('IC_%s'%(item+1))\n",
    "                stat_dict[key][k][subkey].columns=new_name\n",
    "                stat_dict[key][k][subkey]['group'] = subkey\n",
    "\n",
    "for key, value in stat_dict.items():\n",
    "    print(key)\n",
    "    for k,v in value.items():\n",
    "        print(k)\n",
    "        df = pd.concat([v['no'],v['ov']], axis=0)\n",
    "        df = pd.concat([df,v['ob']], axis=0)\n",
    "        if k in ['clustering_coeff', 'btn_centrality', 'PC']:\n",
    "            keys = []\n",
    "            tables = []\n",
    "            for variable in list(df.columns)[0:100]:\n",
    "                m='%s ~ group'%variable\n",
    "                model = ols(m, data=df).fit()\n",
    "                anova_table = sm.stats.anova_lm(model, typ=2)\n",
    "\n",
    "                keys.append(variable)\n",
    "                tables.append(anova_table)\n",
    "\n",
    "            df_anova = pd.concat(tables, keys=keys, axis=0)\n",
    "            raw_p=df_anova['PR(>F)'].dropna()\n",
    "            fdr=st.stats.multitest.fdrcorrection(raw_p, alpha=0.05, method='indep', is_sorted=False)\n",
    "            stat_dict[key][k].update({'full':df, 'anova':df_anova, 'FDR':fdr})\n",
    "        else:\n",
    "            print(df)\n",
    "            keys = []\n",
    "            tables = []\n",
    "            variable='IC_1'\n",
    "            m='%s ~ group'%variable\n",
    "            model = ols(m, data=df).fit()\n",
    "            anova_table = sm.stats.anova_lm(model, typ=2)\n",
    "\n",
    "            keys.append(variable)\n",
    "            tables.append(anova_table)\n",
    "\n",
    "            df_anova = pd.concat(tables, keys=keys, axis=0)\n",
    "            raw_p=df_anova['PR(>F)'].dropna()\n",
    "            fdr=st.stats.multitest.fdrcorrection(raw_p, alpha=0.05, method='indep', is_sorted=False)\n",
    "            stat_dict[key][k].update({'full':df, 'anova':df_anova, 'FDR':fdr})\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stat_dict['NR'].keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for key, value in stat_dict.items():\n",
    "    for subkey,subval in value.items():\n",
    "        for k,v in subval.items():\n",
    "            if k == 'FDR':\n",
    "                s = set(v[0])\n",
    "                if True in s:\n",
    "                    print('there is a significant value here %s %s'%(key,subkey))\n",
    "                    print(stat_dict[key][subkey]['FDR'][1])\n",
    "                    print(stat_dict[key][subkey]['anova'])\n",
    "                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df=stat_dict['MZ']['btn_centrality']['full']\n",
    "m='%s ~ group'%'IC_2'\n",
    "model = ols(m, data=df).fit()\n",
    "anova_table = sm.stats.anova_lm(model, typ=2)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Did not find any differences in the nodal metrics between groups in the not related condition  \n",
    "IC_2 shows significantly different betweenness centrality between the obese and normal weight monozygotic twin subset. Probably due to a false discovery "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# an.adillyofapickle('/Users/gracer/Google Drive/HCP_graph/1200/datasets',stat_dict,'6_stat_dict')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# stat_dict=an.onetoughjar(os.path.join(basepath,'tmp','6_stat_dict_11-20-2019_10-37-43'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "summary_dict['NR']['no'].keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "no_edge_btw=nx.edge_betweenness_centrality(summary_dict['NR']['no']['graphs'], normalized=True, weight='weight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "no_edge_btw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ov_edge_btw=nx.edge_betweenness_centrality(summary_dict['NR']['ov']['graphs'], normalized=True, weight='weight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ob_edge_btw=nx.edge_betweenness_centrality(summary_dict['NR']['ob']['graphs'], normalized=True, weight='weight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "summary_dict['NR']['ob']['edge_btw']=ob_edge_btw\n",
    "summary_dict['NR']['ov']['edge_btw']=ov_edge_btw\n",
    "summary_dict['NR']['no']['edge_btw']=no_edge_btw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nx.set_edge_attributes(summary_dict['NR']['ob']['graphs'], ob_edge_btw, 'betweenness')\n",
    "nx.set_edge_attributes(summary_dict['NR']['ov']['graphs'], ov_edge_btw, 'betweenness')\n",
    "nx.set_edge_attributes(summary_dict['NR']['no']['graphs'], no_edge_btw, 'betweenness')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "an.adillyofapickle('/Users/gracer/Google Drive/HCP_graph/1200/datasets',summary_dict,'5_summary_dict')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def grace_graph(graph, group,  **kwargs):\n",
    "    e,w = zip(*nx.get_edge_attributes(graph, 'weight').items())\n",
    "    if bool(kwargs) == False:\n",
    "        positions = nx.circular_layout(graph)\n",
    "        size = 100\n",
    "        title= \"Modularity and edge weights \\n of average %s graph\"%(group)\n",
    "        save=\"%s_graph.png\"%(group)\n",
    "    else:\n",
    "        if 'edges' in kwargs:\n",
    "            print('this is a betweenness graph')\n",
    "            edges, weights = zip(*nx.get_edge_attributes(graph, 'betweenness').items())\n",
    "        else:\n",
    "            edges, weights = zip(*nx.get_edge_attributes(graph, 'weight').items())\n",
    "        if 'position' in kwargs and kwargs['position']=='spectral':\n",
    "            positions = nx.spectral_layout(graph)\n",
    "            title= \"Spectral modularity and edge weights \\n of average %s graph\"%(group)\n",
    "            save=\"Spectral_%s_graph.png\"%(group)\n",
    "        elif 'position' in kwargs and kwargs['position']=='spring':\n",
    "            positions = nx.spring_layout(graph)\n",
    "            title= \"Spring modularity and edge weights \\n of average %s graph\"%(group)\n",
    "            save=\"Sping_%s_graph.png\"%(group)\n",
    "        else:\n",
    "            positions = nx.circular_layout(graph)\n",
    "            title= \"Circle modularity and edge weights \\n of average %s graph\"%(group)\n",
    "            save=\"Circle_%s_graph.png\"%(group)\n",
    "        if 'metric' in kwargs:\n",
    "            nodes, size = zip(*nx.get_node_attributes(graph, kwargs['metric']).items())\n",
    "        else:\n",
    "            size = 100\n",
    "            title = \"basic\"\n",
    "            save=\"%s_graph.png\"%(group)\n",
    "        if 'thresh' in kwargs:\n",
    "            tile=kwargs['thresh']\n",
    "            purr=np.percentile(w, tile)\n",
    "            print(purr)\n",
    "            graph=an.threshold2(graph,purr)\n",
    "        \n",
    "    nodes, color = zip(*nx.get_node_attributes(graph, 'modules').items()) #if your modules are named different change here\n",
    "    # nodes, names = zip(*nx.get_node_attributes(graph, 'label').items()) #if your modules are named different change here\n",
    "    g=graph\n",
    "    #Figure size\n",
    "    plt.figure(figsize=(80,50))\n",
    "\n",
    "    #draws nodes\n",
    "    color = np.array(color)\n",
    "    n_color=len(list(set(color)))\n",
    "    # nColormap=plt.cm.Set3 #check here if you want different colors https://matplotlib.org/3.1.1/gallery/color/colormap_reference.html\n",
    "    cM=color.max()\n",
    "    cm=color.min()\n",
    "    # get discrete colormap\n",
    "    nColormap = plt.get_cmap('Set3', n_color)\n",
    "\n",
    "    # scaling\n",
    "    sz=np.array(size)\n",
    "    scale=15000/sz.max()\n",
    "    sza=sz*scale\n",
    "    # print(sz.shape)\n",
    "\n",
    "    y=nx.draw_networkx_nodes(g,positions,\n",
    "                           node_color=color,\n",
    "                           node_size=sza,\n",
    "                           alpha=0.8,\n",
    "                           cmap= nColormap,\n",
    "                           vmin=cm ,vmax=cM)\n",
    "\n",
    "    #Styling for labels\n",
    "    nx.draw_networkx_labels(g, positions,\n",
    "                            # labels = label_dict,\n",
    "                            font_size=50,\n",
    "                            font_family='sans-serif',\n",
    "                            fontweight = 'bold')\n",
    "\n",
    "    #draw edges\n",
    "#     print(weights)\n",
    "    weights=np.array(weights)\n",
    "    eColormap=plt.cm.gist_rainbow #check here if you want different colors https://matplotlib.org/3.1.1/gallery/color/colormap_reference.html\n",
    "    # scaling\n",
    "    wt=list(set(weights))\n",
    "    wt=np.array(wt)\n",
    "    wt2=-np.sort(-wt)\n",
    "    wt0=wt2[1]\n",
    "\n",
    "    escale=1/wt0\n",
    "    esza=weights*escale\n",
    "    E=list(set(esza))\n",
    "    E2=-np.sort(-np.array(E))\n",
    "    M=E2[1]\n",
    "    m=esza.min()\n",
    "\n",
    "    x=nx.draw_networkx_edges(g, positions,\n",
    "                           edge_list=edges,\n",
    "                           style='solid',\n",
    "                           width = np.square(esza)*5,\n",
    "                           edge_color = esza,\n",
    "                           edge_cmap=eColormap,\n",
    "                           edge_vmin=m,\n",
    "                           edge_vmax=M)\n",
    "\n",
    "    #COLORBAR STUFF\n",
    "    node_bar=plt.colorbar(y, label='Module value')\n",
    "\n",
    "    tick_locs = (np.arange(n_color) + 0.5)*(n_color-1)/n_color\n",
    "    node_bar.set_ticks(tick_locs)\n",
    "\n",
    "    # set tick labels (as before)\n",
    "    node_bar.set_ticklabels(np.arange(n_color))\n",
    "\n",
    "\n",
    "    sm = plt.cm.ScalarMappable(cmap=eColormap, norm=plt.Normalize(vmin = m, vmax=M))\n",
    "    sm._A = []\n",
    "    edge_bar=plt.colorbar(sm)\n",
    "\n",
    "    for l in edge_bar.ax.yaxis.get_ticklabels():\n",
    "        l.set_size(50)\n",
    "    for l in node_bar.ax.yaxis.get_ticklabels():\n",
    "        l.set_size(50)\n",
    "        l.set_verticalalignment('center')\n",
    "\n",
    "    node_bar.set_label('Modularity',fontsize = 50)\n",
    "    edge_bar.set_label('Strength of edge weight',fontsize = 50)\n",
    "    # Final plot stuff\n",
    "    plt.axis('off')\n",
    "\n",
    "    plt.title(title, fontsize = 100)\n",
    "    basepath='/Users/gracer/Google Drive/HCP/HCP_graph/1200/images'\n",
    "\n",
    "    plt.savefig(os.path.join(basepath,save), format=\"PNG\")\n",
    "    plt.show()\n",
    "    return()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "summary_dict['NR']['ob']['graphs'].nodes(data=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "grace_graph(summary_dict['NR']['ob']['graphs'], 'Obese',  thresh= 0, metric = 'centrality', position='circle', edges=True)\n",
    "\n",
    "grace_graph(summary_dict['NR']['ov']['graphs'], 'Overweight',  thresh= 0, metric = 'centrality', position='circle', edges=True)\n",
    "\n",
    "grace_graph(summary_dict['NR']['no']['graphs'], 'Normal weight',  thresh= 0, metric = 'centrality', position='circle', edges=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Checking functional connectivity "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_matrices(matrices, matrix_kind):\n",
    "    n_matrices = len(matrices)\n",
    "    fig = plt.figure(figsize=(n_matrices * 4, 4))\n",
    "    for n_subject, matrix in enumerate(matrices):\n",
    "        plt.subplot(1, n_matrices, n_subject + 1)\n",
    "        matrix = matrix.copy()  # avoid side effects\n",
    "        # Set diagonal to zero, for better visualization\n",
    "        np.fill_diagonal(matrix, 0)\n",
    "        vmax = np.max(np.abs(matrix))\n",
    "        title = '{0}, subject {1}'.format(matrix_kind, n_subject)\n",
    "        plotting.plot_matrix(matrix, vmin=-vmax, vmax=vmax, cmap='RdBu_r',\n",
    "                             title=title, figure=fig, colorbar=False)\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "basepath='/Users/gracer/Google Drive/HCP_graph/1200/datasets/'\n",
    "file_dict=an.onetoughjar(os.path.join(basepath,'tmp','file_dict_11-14-2019_10-07-24'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "file_dict['NR']['ov']['134223']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "listcorr_dict={'MZ':{'no':[],'ov':[],'ob':[]},'DZ':{'no':[],'ov':[],'ob':[]},'NR':{'no':[],'ov':[],'ob':[]}}\n",
    "for key, value in file_dict.items():\n",
    "    for subkey, subval in value.items():\n",
    "        print(subkey)\n",
    "        for k,v in subval.items():\n",
    "            listcorr_dict[key][subkey].append(v.to_numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "correlation_measure = ConnectivityMeasure(kind='correlation')\n",
    "\n",
    "for key, value in listcorr_dict['NR'].items():\n",
    "    correlation_matrices = correlation_measure.fit_transform(value)\n",
    "    # All individual coefficients are stacked in a unique 2D matrix.\n",
    "    print('Correlations of %s subjects are stacked in an array of shape {0}'%key\n",
    "          .format(correlation_matrices.shape))\n",
    "    mean_correlation_matrix = correlation_measure.mean_\n",
    "    print('Mean correlation has shape {0}.'.format(mean_correlation_matrix.shape))\n",
    "\n",
    "\n",
    "    plt.figure(figsize=(40,25))\n",
    "    ax = sns.heatmap(mean_correlation_matrix, linewidth=0.5, cmap='coolwarm')\n",
    "\n",
    "    #Save the figure\n",
    "    # ax.figure.savefig(\"/Users/jennygilbert/Documents/betaseries_bevel/reward_coor_mat.png\")\n",
    "\n",
    "    #plot_matrices(rwd_correlation_matrices[:5], 'reward')\n",
    "    #plot_matrices(rwd_mean_correlation_matrix, 'reward')\n",
    "\n",
    "\n",
    "\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def corrector(x, alpha):\n",
    "    results=x[1].ravel()\n",
    "    mask = np.isfinite(results)\n",
    "    pval_corrected = np.empty(results.shape)\n",
    "    pval_corrected.fill(np.nan)\n",
    "    pval_corrected[mask] = st.stats.multitest.multipletests(results[mask],alpha=alpha,method='fdr_bh')[1]\n",
    "    p=np.reshape(pval_corrected, (100, 100))\n",
    "    print(np.nanmin(p))\n",
    "    ps = 1-p\n",
    "    print(np.nanmax(ps))\n",
    "    coor_fig(ps)\n",
    "    return(p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def coor_fig(df):\n",
    "    plt.figure(figsize=(40,25))\n",
    "    m=np.nanmin(df)\n",
    "    M=np.nanmax(df)\n",
    "    print('The max p value is %f'%M)\n",
    "    sns.heatmap(df, linewidth=0.5, \n",
    "                vmin=m, vmax=1, \n",
    "                cmap=sns.cubehelix_palette(10000), \n",
    "                cbar_kws={'ticks': [0.0, 0.2, 0.4, 0.5, 0.7, 0.8,0.975 ,1.0]})\n",
    "    return(plt.show())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a=listcorr_dict['NR']['no']\n",
    "b=listcorr_dict['NR']['ov']\n",
    "c=listcorr_dict['NR']['ob']\n",
    "test=spy_stats.f_oneway(a, b, c)\n",
    "anova_results=corrector(test, 0.05)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Between no and ov & no and ob\n",
    "p=0.05/2  \n",
    "p=0.025"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "no_ov=spy_stats.ttest_ind(a, b, nan_policy='omit')\n",
    "no_ov_results=corrector(no_ov, 0.025)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "no_ob=spy_stats.ttest_ind(a, c, nan_policy='omit')\n",
    "no_ob_results=corrector(no_ob, 0.025)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary\n",
    "There appears to be no differences in the graph metrics between nodes. Nor a difference in functional connectivity"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Between modules metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# basepath='/Users/gracer/Google Drive/HCP_graph/1200/datasets/'\n",
    "# #Load data from pickle if needed\n",
    "# summary_dict=an.onetoughjar(os.path.join(basepath,'tmp','summary_dict_11-14-2019_04-33-33'))\n",
    "for key, value in summary_dict.items():\n",
    "    for k,v in value.items():\n",
    "        # community.induced_graph(partition dictionary, graph)\n",
    "         comm_graph = community.induced_graph(v['modules']['partition'], v['graphs'])\n",
    "         v.update(comm_graph = comm_graph)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "summary_dict['NR']['no']['comm_graph'].nodes(data=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "btw_no=nx.edge_betweenness_centrality(summary_dict['NR']['no']['comm_graph'], weight=True,  normalized = True)\n",
    "btw_no"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "btw_ov=nx.edge_betweenness_centrality(summary_dict['NR']['ov']['comm_graph'], weight=True, normalized = True)\n",
    "btw_ov"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "btw_ob=nx.edge_betweenness_centrality(summary_dict['NR']['ob']['comm_graph'], weight=True, normalized = True)\n",
    "btw_ob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def corr_mod(mat):\n",
    "    plt.figure(figsize=(5,5))\n",
    "    ax = sns.heatmap(mat, linewidth=0.5, cmap='coolwarm')\n",
    "    return(plt.show())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "A = nx.to_numpy_matrix(summary_dict['NR']['no']['comm_graph'])\n",
    "B = nx.to_numpy_matrix(summary_dict['NR']['ov']['comm_graph'])\n",
    "C = nx.to_numpy_matrix(summary_dict['NR']['ob']['comm_graph'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nx.to_pandas_adjacency(summary_dict['NR']['no']['comm_graph'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "corr_mod(A)\n",
    "corr_mod(B)\n",
    "corr_mod(C)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def module_fig(G, Type):\n",
    "    edges,weights = zip(*nx.get_edge_attributes(G,'weight').items())\n",
    "    #nodes, size = zip(*nx.get_node_attributes(G,'clustering').items())\n",
    "\n",
    "    positions=nx.circular_layout(G)\n",
    "    plt.figure(figsize=(80,50))\n",
    "    ### NODES ####\n",
    "    color = np.array(list(G.nodes))\n",
    "    color = np.array(color)\n",
    "    n_color=len(list(set(color)))\n",
    "    nColormap = plt.get_cmap('Set3', n_color)\n",
    "    cM=color.max()\n",
    "    cm=color.min()\n",
    "    y=nx.draw_networkx_nodes(G,positions,\n",
    "                           node_color=color,\n",
    "                           node_size=15000,\n",
    "                           alpha=1.0,\n",
    "                           cmap= nColormap,\n",
    "                           vmin=cm,vmax=cM )\n",
    "\n",
    "    #Styling for labels\n",
    "    nx.draw_networkx_labels(G, positions, font_size=100,\n",
    "                            font_family='sans-serif', fontweight = 'bold')\n",
    "    \n",
    "    ### EDGES ####\n",
    "    weights=np.array(weights)\n",
    "    # scaling\n",
    "    wt=list(set(weights))\n",
    "    wt=np.array(wt)\n",
    "    wt2=-np.sort(-wt)\n",
    "    wt0=wt2[1]\n",
    "\n",
    "    escale=1/wt0\n",
    "    esza=weights*escale\n",
    "    E=list(set(esza))\n",
    "    E2=-np.sort(-np.array(E))\n",
    "    M=E2[1]\n",
    "    m=esza.min()\n",
    "    \n",
    "    \n",
    "    eColormap=plt.cm.gist_rainbow\n",
    "    \n",
    "    x=nx.draw_networkx_edges(G, positions, \n",
    "                             edge_list=edges,\n",
    "                             style='solid', \n",
    "                             width = np.square(esza*5),\n",
    "                             edge_color = weights, \n",
    "                             edge_vmin=m, \n",
    "                             edge_vmax=M, \n",
    "                             edge_cmap= eColormap)\n",
    "\n",
    "    \n",
    "    node_bar=plt.colorbar(y, label='Module value')\n",
    "    \n",
    "    tick_locs = (np.arange(n_color) + 0.5)*(n_color-1)/n_color\n",
    "    node_bar.set_ticks(tick_locs)\n",
    "\n",
    "    # set tick labels (as before)\n",
    "    node_bar.set_ticklabels(np.arange(n_color))\n",
    "\n",
    "\n",
    "    sm = plt.cm.ScalarMappable(cmap=eColormap, norm=plt.Normalize(vmin = m, vmax=M))\n",
    "    sm._A = []\n",
    "    edge_bar=plt.colorbar(sm)\n",
    "\n",
    "    for l in edge_bar.ax.yaxis.get_ticklabels():\n",
    "        l.set_size(50)\n",
    "    for l in node_bar.ax.yaxis.get_ticklabels():\n",
    "        l.set_size(50)\n",
    "        l.set_verticalalignment('center')\n",
    "\n",
    "    node_bar.set_label('Modularity',fontsize = 50)\n",
    "    edge_bar.set_label('Strength of edge weight',fontsize = 50)\n",
    "    \n",
    "    plt.title(\"Module Connectivity Weights %s\"%Type, fontsize = 100)\n",
    "    plt.axis('off')\n",
    "    basepath='/Users/gracer/Google Drive/HCP_graph/1200/images'\n",
    "    plt.savefig(os.path.join(basepath,\"modularity_%s.png\"%(Type)), format=\"PNG\")\n",
    "    # plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "basepath"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "an.module_fig(summary_dict['NR']['no']['comm_graph'], 'Normal', basepath = basepath)\n",
    "an.module_fig(summary_dict['NR']['ov']['comm_graph'], 'Overweight',basepath = basepath)\n",
    "an.module_fig(summary_dict['NR']['ob']['comm_graph'], 'Obese',basepath = basepath)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating subgraphs per module"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "unique, counts = np.unique(summary_dict['NR']['no']['modules']['values'], return_counts=True)\n",
    "print(np.asarray((unique, counts)).T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mod_dict={'MZ':{'no':{}, 'ov':{}, 'ob':{}},\n",
    "           'DZ':{'no':{}, 'ov':{}, 'ob':{}},\n",
    "           'NR':{'no':{}, 'ov':{}, 'ob':{}}\n",
    "         }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for key, values in summary_dict.items():\n",
    "    print(key)\n",
    "    for k,v in values.items():\n",
    "        print(k)\n",
    "        unique, counts = np.unique(summary_dict[key][k]['modules']['values'], return_counts=True)\n",
    "        for i in unique:\n",
    "            mod_dict[key][k].update({i:[]})\n",
    "        for q, w in summary_dict[key][k]['modules']['partition'].items():\n",
    "            mod_dict[key][k][w].append(q)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "mod_dict['NR']['no']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "summary_dict['NR']['no'].keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "subgraph_dict={'MZ':{'no':{}, 'ov':{}, 'ob':{}},\n",
    "           'DZ':{'no':{}, 'ov':{}, 'ob':{}},\n",
    "           'NR':{'no':{}, 'ov':{}, 'ob':{}}\n",
    "         }\n",
    "for key, value in mod_dict.items():\n",
    "    print(key)\n",
    "    for k, v in value.items():\n",
    "        print(k)\n",
    "        G=summary_dict[key][k]['graphs']\n",
    "        for q,w in v.items():\n",
    "            print(q)\n",
    "            print(w)\n",
    "#             H=nx.subgraph_view(G,filter_node=w)\n",
    "            H = G.subgraph(w).copy()\n",
    "            subgraph_dict[key][k][q]=H\n",
    "            \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "subgraph_dict['NR']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "subgraph_dict['NR']['no'][6].nodes(data=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def threshold(G, min_correlation):\n",
    "    ##Creates a copy of the graph\n",
    "    H = G.copy()\n",
    "    ##Checks all the edges and removes some based on corr_direction\n",
    "    for stock1, stock2, weight in list(G.edges(data=True)):\n",
    "        ##if we only want to see the positive correlations we then delete the edges with weight smaller than 0\n",
    "#         print(min_correlation)\n",
    "        if weight[\"weight\"] < min_correlation:\n",
    "            H.remove_edge(stock1, stock2)\n",
    "    return(H)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#subgraph_dict=an.onetoughjar(os.path.join(basepath,'tmp','7_subgraph_dict_11-20-2019_10-40-04'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def inner_mod(graph, metric, group, tile, style):\n",
    "    e,w = zip(*nx.get_edge_attributes(graph, 'weight').items())\n",
    "    purr=np.percentile(w, tile)\n",
    "    print(purr)\n",
    "    g=an.threshold2(graph,purr)\n",
    "\n",
    "    edges,weights = zip(*nx.get_edge_attributes(g, 'weight').items())\n",
    "    weights=np.array(weights)\n",
    "    print(weights.min())\n",
    "    \n",
    "    nodes, color = zip(*nx.get_node_attributes(g, metric).items()) \n",
    "    nodes, size = zip(*nx.get_node_attributes(g, metric).items())\n",
    "    nodes, positions = zip(*nx.get_node_attributes(g,'modules').items())\n",
    "    #positions\n",
    "    if style == 'spectral':\n",
    "        positions=nx.spectral_layout(g) #this is defining a circluar graph, if you want a different one you change the circular part of this line\n",
    "    elif style == 'spring':\n",
    "        positions=nx.spring_layout(g)\n",
    "    else:\n",
    "        positions=nx.circular_layout(g)\n",
    "    #Figure size\n",
    "    plt.figure(figsize=(80,50))\n",
    "\n",
    "    #draws nodes\n",
    "    color = np.array(color)\n",
    "    colz=scipy.stats.zscore(color)\n",
    "    nColormap=plt.cm.cool #check here if you want different colors https://matplotlib.org/3.1.1/gallery/color/colormap_reference.html\n",
    "    cM=colz.max()\n",
    "    cm=colz.min()\n",
    "    \n",
    "\n",
    "    scale=15000/colz.max()\n",
    "    y=nx.draw_networkx_nodes(g,positions,\n",
    "                           node_color=colz,\n",
    "                           node_size=np.square(colz)*scale,\n",
    "                           alpha=0.8,\n",
    "                           cmap= nColormap,\n",
    "                           vmin=cm ,vmax=cM)\n",
    "\n",
    "    #Styling for labels\n",
    "    keeps=g.nodes()\n",
    "    dict_you_want = { your_key: note_dict[your_key] for your_key in keeps }\n",
    "    nx.draw_networkx_labels(g, positions, font_size=50,\n",
    "                            labels=dict_you_want,\n",
    "                            font_family='sans-serif', \n",
    "                            fontweight = 'bold')\n",
    "\n",
    "    #draw edges\n",
    "    weights=np.array(weights)\n",
    "    eColormap=plt.cm.gist_rainbow #check here if you want different colors https://matplotlib.org/3.1.1/gallery/color/colormap_reference.html\n",
    "    # scaling\n",
    "    wt=list(set(weights))\n",
    "    wt=np.array(wt)\n",
    "    wt2=-np.sort(-wt)\n",
    "    wt0=wt2[1]\n",
    "\n",
    "    escale=1/wt0\n",
    "    esza=weights*escale\n",
    "    E=list(set(esza))\n",
    "    E2=-np.sort(-np.array(E))\n",
    "    M=E2[1]\n",
    "    m=esza.min()\n",
    "\n",
    "    x=nx.draw_networkx_edges(g, positions,\n",
    "                           edge_list=edges,\n",
    "                           style='solid',\n",
    "                           width = np.square(esza)*5,\n",
    "                           edge_color = esza,\n",
    "                           edge_cmap=eColormap,\n",
    "                           edge_vmin=m,\n",
    "                           edge_vmax=M)\n",
    "\n",
    "    #format the colorbar\n",
    "    node_bar=plt.colorbar(y, label='Module value')\n",
    "\n",
    "    sm = plt.cm.ScalarMappable(cmap=eColormap, norm=plt.Normalize(vmin = m, vmax=M))\n",
    "    sm._A = []\n",
    "    edge_bar=plt.colorbar(sm)\n",
    "\n",
    "\n",
    "    for l in edge_bar.ax.yaxis.get_ticklabels():\n",
    "        l.set_size(50)\n",
    "    for l in node_bar.ax.yaxis.get_ticklabels():\n",
    "        l.set_size(50)\n",
    "        \n",
    "    node_bar.set_label('%s'%metric,fontsize = 50)\n",
    "    edge_bar.set_label('Strength of edge weight',fontsize = 50)\n",
    "\n",
    "    plt.axis('off')\n",
    "    plt.title(\"%s and edge weights of \\n average %s graph\"%(metric, group), fontsize = 100)\n",
    "    basepath='/Users/gracer/Google Drive/HCP/HCP_graph/1200/images'\n",
    "\n",
    "    plt.savefig(os.path.join(basepath,\"%s_%s_%s.png\"%(metric,style,group)), format=\"PNG\")\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "subgraph_dict['NR']['ov']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "inner_mod(subgraph_dict['NR']['ov'][8], 'centrality', '%s module %s'%('ov','8'), 40, 'circle')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "interest = [1,2,4,5,6,8]\n",
    "for i in interest:\n",
    "    for key, value in subgraph_dict['NR'].items():    \n",
    "        print(key)\n",
    "        inner_mod(value[i], 'centrality', '%s module %s'%(key,i), 40, 'circle')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#an.adillyofapickle('/Users/gracer/Google Drive/HCP_graph/1200/datasets',subgraph_dict,'7_subgraph_dict')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "subgraph_dict['NR']['no'][0].nodes(data=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "modstat_dict={'MZ':{'no':{}, 'ov':{}, 'ob':{}},\n",
    "           'DZ':{'no':{}, 'ov':{}, 'ob':{}},\n",
    "           'NR':{'no':{}, 'ov':{}, 'ob':{}}\n",
    "         }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for key, value in subgraph_dict.items():\n",
    "    print(key)\n",
    "    for subkey,subval in value.items():\n",
    "        print(subkey)\n",
    "        liist=list(subgraph_dict[key][subkey].keys())\n",
    "        for i in liist:\n",
    "            modstat_dict[key][subkey].update({i:[]})\n",
    "        for k,v in subval.items():\n",
    "            print(k)\n",
    "            print(subkey)\n",
    "#             print(dict(v.nodes(data=True)))\n",
    "            modstat_dict[key][subkey][k]=pd.DataFrame.from_dict(dict(subgraph_dict[key][subkey][k].nodes(data=True)), orient='index')\n",
    "            modstat_dict[key][subkey][k]['group']=subkey\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list(modstat_dict['NR']['ov'].values())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pandas_dict={'MZ':{'no':{}, 'ov':{}, 'ob':{}},\n",
    "           'DZ':{'no':{}, 'ov':{}, 'ob':{}},\n",
    "           'NR':{'no':{}, 'ov':{}, 'ob':{}}\n",
    "         }\n",
    "for key, item in modstat_dict.items():\n",
    "    print(key)\n",
    "    for k, i in item.items():\n",
    "        print(i)\n",
    "        pandas_dict[key][k]=pd.concat(list(modstat_dict['NR'][k].values()))\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "pandas_dict['NR']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "an.adillyofapickle('/Users/gracer/Google Drive/HCP_graph/1200/datasets',pandas_dict,'8_modulemetrics_dict')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test=an.onetoughjar(os.path.join(basepath,'tmp','8_modulemetrics_dict_11-20-2019_10-40-13'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df=pd.concat(list(pandas_dict['NR'].values()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['group'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['group'] = df['group'].astype('category')\n",
    "df['group'].cat.reorder_categories(['no', 'ov','ob'], inplace=True)\n",
    "df['modules'] = df['modules'].astype('category')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# basepath = '/Users/gracer/Google Drive/HCP/HCP_graph/1200/datasets/'\n",
    "# file_dict=an.onetoughjar(os.path.join(basepath,'tmp','5_summary_dict_07-31-2020_12-26-08'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pandas_dict['NR']['no'].keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def zed(dicti):\n",
    "    tmp_dict={}\n",
    "    for key, value in dicti.items():\n",
    "        print(key)\n",
    "        for k, v in value['modules'].items():\n",
    "            print(k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "zed(pandas_dict['NR'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def zed(dicti):\n",
    "    tmp_dict={}\n",
    "    for key, item in dicti.items():\n",
    "        print(key)\n",
    "        for subkey, value in item.items():\n",
    "            print(subkey)\n",
    "            if subkey in ['modules']:\n",
    "                for x, y in value.items():\n",
    "#                     print(x)\n",
    "                    if x == 'partition':\n",
    "                        df=pd.DataFrame.from_dict(y, orient='index')\n",
    "                        df.rename({0: 'module'}, axis=1, inplace = True)\n",
    "                        df['group']=key\n",
    "                    if x == 'zdegree':\n",
    "                        df['zdegree']=y\n",
    "                        tmp_dict[key]=df\n",
    "                    else:\n",
    "                        continue\n",
    "    total_df=pd.concat(list(tmp_dict.values()))\n",
    "    return(total_df)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_z=zed(pandas_dict['NR'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_result = pd.merge(df, df_z, left_index=True, right_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv(os.path.join(basepath, 'tmp', 'mod_data.csv'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary\n",
    "No differences in the graph metrics between modules between groups"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "subgraph_dict['NR']['no'].keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "subgraph_dict['NR']['no']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "edgestat_dict={'MZ':{'no':{}, 'ov':{}, 'ob':{}},\n",
    "           'DZ':{'no':{}, 'ov':{}, 'ob':{}},\n",
    "           'NR':{'no':{}, 'ov':{}, 'ob':{}}\n",
    "         }\n",
    "for key, value in subgraph_dict['NR'].items():\n",
    "    print(key)        \n",
    "    liist=list(subgraph_dict['NR'][key].keys())\n",
    "    for i in liist:\n",
    "        modstat_dict['NR'][key].update({i:[]})\n",
    "    for k,v in subval.items():\n",
    "        print(k)\n",
    "        print(subkey)\n",
    "        edgestat_dict['NR'][key][k]=nx.to_numpy_matrix(v)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "edgestat_dict['NR']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "an.adillyofapickle('/Users/gracer/Google Drive/HCP_graph/1200/datasets',edgestat_dict,'9_edgestat_dict')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "edgestat_dict['NR']['ov']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "edgestat_dict['NR']['no'].keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for key, value in edgestat_dict['NR'].items():\n",
    "    for k,v in value.items():\n",
    "        print(\"This is the %s for the %s module\"%(key,k))\n",
    "#         print(edgestat_dict['NR'][key][k])\n",
    "        corr_mod(edgestat_dict['NR'][key][k])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def corrector(x, alpha):\n",
    "    sh=x.shape\n",
    "    print(sh)\n",
    "    results=x[1].ravel()\n",
    "    mask = np.isfinite(results)\n",
    "    pval_corrected = np.empty(results.shape)\n",
    "    pval_corrected.fill(np.nan)\n",
    "    pval_corrected[mask] = st.stats.multitest.multipletests(results[mask],alpha=alpha,method='fdr_bh')[1]\n",
    "    p=np.reshape(pval_corrected, sh)\n",
    "    print(np.nanmin(p))\n",
    "    ps = 1-p\n",
    "    print(np.nanmax(ps))\n",
    "    coor_fig(ps)\n",
    "    return(p)\n",
    "\n",
    "def coor_fig(df):\n",
    "    plt.figure(figsize=(40,25))\n",
    "    m=np.nanmin(df)\n",
    "    M=np.nanmax(df)\n",
    "    print('The max p value is %f'%M)\n",
    "    sns.heatmap(df, linewidth=0.5, \n",
    "                vmin=m, vmax=1, \n",
    "                cmap=sns.cubehelix_palette(10000), \n",
    "                cbar_kws={'ticks': [0.0, 0.2, 0.4, 0.5, 0.7, 0.8,0.975 ,1.0]})\n",
    "    return(plt.show())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compar(di,mod):\n",
    "    a=di['NR']['no'][mod]\n",
    "    print(a)\n",
    "    b=di['NR']['ov'][mod]\n",
    "    c=di['NR']['ob'][mod]\n",
    "    test=spy_stats.f_oneway(a, b, c)\n",
    "    print(test[1])\n",
    "    p=corrector(test[1], 0.05)\n",
    "#     coor_fig(p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "di=edgestat_dict\n",
    "mod=0\n",
    "a=di['NR']['no'][mod]\n",
    "b=di['NR']['ov'][mod]\n",
    "c=di['NR']['ob'][mod]\n",
    "test=spy_stats.f_oneway(a, b, c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "no_ob=spy_stats.ttest_ind(a, c, nan_policy='omit')\n",
    "no_ob_results=corrector(no_ob[1], 0.025)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "compar(edgestat_dict, 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Between no and ov & no and ob\n",
    "p=0.05/2  \n",
    "p=0.025"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "no_ov=spy_stats.ttest_ind(a, b, nan_policy='omit')\n",
    "no_ov_results=corrector(no_ov, 0.025)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "no_ob=spy_stats.ttest_ind(a, c, nan_policy='omit')\n",
    "no_ob_results=corrector(no_ob, 0.025)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Within module metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Edge analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "latest_file3=an.find_latest(os.path.join(basepath,'tmp'),'9_*')\n",
    "save_dict=an.onetoughjar(latest_file3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_dict['NR']['no'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for key, item in save_dict['NR'].items():\n",
    "    for subkey, value in item.items():\n",
    "        print(subkey)\n",
    "        if subkey in ['mean_FC']:\n",
    "            tmp=pd.DataFrame.from_dict(value, orient='index')\n",
    "            tmp['group'] = '%s'%key\n",
    "            tmp.to_csv(os.path.join(basepath,'tmp','%s_%s_data_per_sub.csv'%(key,subkey)), sep=',')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Looking at modules 8/7/2020"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "basepath='/Users/gracer/Google Drive/HCP/HCP_graph/1200/datasets/'\n",
    "latest_file=an.find_latest(os.path.join(basepath,'tmp'),'6_*')\n",
    "submod_dict=an.onetoughjar(latest_file)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "submod_dict['no'].keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "z={}\n",
    "for group, dat in submod_dict.items():\n",
    "    print(group)\n",
    "    z[group]={}\n",
    "    for module, data in dat.items():\n",
    "        print(module)\n",
    "        z[group][module]=data.join(labels)\n",
    "no=pd.concat(list(z['no'].values()))\n",
    "ov=pd.concat(list(z['ov'].values()))\n",
    "ob=pd.concat(list(z['ob'].values()))\n",
    "total=pd.concat([no,ov,ob])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x=total[['zDegree','group','area']].groupby(['area','group'])\n",
    "x.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "latest_file2=an.find_latest(os.path.join(basepath,'tmp'),'5_*')\n",
    "summary_dict=an.onetoughjar(latest_file2)\n",
    "summary_dict=summary_dict['NR']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for k,v in summary_dict.items():\n",
    "    # community.induced_graph(partition dictionary, graph)\n",
    "     comm_graph = community.induced_graph(v['modules']['partition'], v['graphs'])\n",
    "     v.update(comm_graph = comm_graph)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "summary_dict['no']['comm_graph'].edges(data=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "no_df = nx.to_pandas_edgelist(summary_dict['no']['comm_graph'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "edges = {}\n",
    "\n",
    "for group, stuff in summary_dict.items():\n",
    "    print(group)\n",
    "    _df = nx.to_pandas_edgelist(stuff['comm_graph'])\n",
    "#     _df[(_df['source'] != _df['target']), 'weight'] == 0\n",
    "    _df.loc[(_df['source'] == _df['target']), 'weight'] = 0\n",
    "\n",
    "    _df['group']=group\n",
    "    edges[group]=_df\n",
    "\n",
    "edge_df=pd.concat(list(edges.values()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "edge_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def zscore(col):\n",
    "    col_z = (col - col.mean())/col.std(ddof=0)\n",
    "    return(col_z)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "edge_df['z_weight']=zscore(edge_df['weight'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "edge_df['z_weight'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# edge_df\n",
    "%matplotlib inline\n",
    "fig, ax = plt.subplots()\n",
    "edge_df['z_weight'].plot(ax=ax, kind='bar')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for k,v in summary_dict.items():\n",
    "    test=edge_df[edge_df['group']==k]\n",
    "    keyz = list(zip(test['source'],test['target']))\n",
    "    values=test['z_weight']\n",
    "    up_dict={}\n",
    "    for i in range(len(keyz)):\n",
    "        up_dict[keyz[i]]={'z_edge':values[i]}\n",
    "    nx.set_edge_attributes(v['comm_graph'], up_dict)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "summary_dict['ob']['comm_graph'].edges(data=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "an.module_fig(summary_dict['no']['modules']['graph'], 'Normal', basepath)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 8/13/20 adding atlas info\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "basepath='/Users/gracer/Google Drive/HCP/HCP_graph/1200/datasets/'\n",
    "latest_file2=an.find_latest(os.path.join(basepath,'tmp'),'6_*')\n",
    "submod_dict=an.onetoughjar(latest_file2)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = pd.read_csv(os.path.join(basepath,'tmp','mod_labels.csv'), sep=',')\n",
    "labels.set_index('Index', inplace=True)\n",
    "\n",
    "note_dict={}\n",
    "for i,j in labels.iterrows():\n",
    "    print(i)\n",
    "    print(j['area'])\n",
    "    note_dict[i]=j['area']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "submod_dict.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "submod_dict['no']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "z={}\n",
    "for group, dat in submod_dict.items():\n",
    "    print(group)\n",
    "    z[group]={}\n",
    "    for module, data in dat.items():\n",
    "        print(module)\n",
    "        z[group][module]=data.join(labels)\n",
    "no=pd.concat(list(z['no'].values()))\n",
    "ov=pd.concat(list(z['ov'].values()))\n",
    "ob=pd.concat(list(z['ob'].values()))\n",
    "total=pd.concat([no,ov,ob])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "total.rename(columns={'Unnamed: 2': 'ROI'}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p='/Users/gracer/Google Drive/HCP/HCP_graph/1200/'\n",
    "atlas=pd.read_csv(os.path.join(p,'brains','atlas.csv'), sep=',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "atlas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_df = total.merge(atlas[['X','Y','Z','ROI']], left_on='ROI', right_on = 'ROI', how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "total.join(atlas, on='ROI')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Using visbrain to look at the cifti files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scene creation\n",
    "sc = SceneObj(bgcolor='black', size=(1400, 1000))\n",
    "# Colorbar default arguments. See `visbrain.objects.ColorbarObj`\n",
    "CBAR_STATE = dict(cbtxtsz=12, txtsz=10., width=.1, cbtxtsh=3.,\n",
    "                  rect=(-.3, -2., 1., 4.))\n",
    "KW = dict(title_size=14., zoom=1.2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download the annotation file of the left hemisphere lh.aparc.a2009s.annot\n",
    "path_to_file1 = download_file('lh.aparc.a2009s.annot', astype='example_data')\n",
    "# Define the brain object (now you should know how to do it)\n",
    "b_obj_parl = BrainObj('inflated', hemisphere='left', translucent=False)\n",
    "# Print parcellates included in the file\n",
    "# print(b_obj_parl.get_parcellates(path_to_file1))\n",
    "# Finally, parcellize the brain and add the brain to the scene\n",
    "b_obj_parl.parcellize(path_to_file1)\n",
    "sc.add_to_subplot(b_obj_parl, row=1, col=1, rotate='left',\n",
    "                  title='Parcellize using the Desikan Atlas', **KW)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download the lh.sig.nii.gz file\n",
    "file = download_file('lh.sig.nii.gz', astype='example_data')\n",
    "# Define the [...] you know\n",
    "b_obj_fmri = BrainObj('inflated', translucent=False, sulcus=True)\n",
    "# Add fMRI activation and hide every activation that is under 5.\n",
    "b_obj_fmri.add_activation(file=file, clim=(5., 20.), hide_under=5,\n",
    "                          cmap='viridis', hemisphere='left')\n",
    "sc.add_to_subplot(b_obj_fmri, row=2, col=1, title='Add fMRI activation',\n",
    "                  rotate='left', **KW)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Link the rotation of subplots (row=0, col=1) and (row=1, col=2)\n",
    "# sc.link((0, 1), (1, 2))\n",
    "# Screenshot of the scene\n",
    "# sc.screenshot('ex_brain_obj.png', transparent=True)\n",
    "\n",
    "sc.preview()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
